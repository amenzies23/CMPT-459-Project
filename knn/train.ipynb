{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c731117",
   "metadata": {},
   "source": [
    "# K-NN Training Overview\n",
    "This notebook implements a full supervised machine-learning pipeline for plant-health classification using k-Nearest Neighbors (k-NN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38846436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from typing import List\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from core.preprocessing import load_and_preprocess_data\n",
    "from core.outlier_detection import remove_outliers\n",
    "from core.feature_selection import select_features\n",
    "from core.classification import (\n",
    "    classify_with_knn,\n",
    "    classify_with_knn_without_hyperparameter,\n",
    ")\n",
    "from core.visualization import (\n",
    "    visualize_ground_truth,\n",
    "    visualize_knn_decision_boundary,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f808dc09",
   "metadata": {},
   "source": [
    "## Setting Random Seeds\n",
    "Ensures that any randomness in preprocessing or clustering is reproducible.\n",
    "This allows consistent results when rerunning the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0189c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc07859",
   "metadata": {},
   "source": [
    "## Data Loading & Preprocessing\n",
    "Here, we load the plant-health dataset and perform basic preprocessing steps required before clustering.\n",
    "We:\n",
    "- Reads the CSV file.\n",
    "- Removes non-informative columns (`Timestamp`, `Plant_ID`).\n",
    "- Splits data into features (`X`) and labels (`y`).\n",
    "- Fills missing values (if any) using column means.\n",
    "- Encodes the target variable using `LabelEncoder` (for visualization).\n",
    "- Standardizes numerical features using `StandardScaler` and returns both raw and scaled versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw, X_scaled, y, label_encoder, scaler = load_and_preprocess_data(\n",
    "    \"../data/plant_health_data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bce72e",
   "metadata": {},
   "source": [
    "## Outlier Removal\n",
    "Identify and remove anomalous samples from a dataset using the Local Outlier Factor (LOF) algorithm. \n",
    "It takes a scaled feature matrix (`X_scaled`) and corresponding labels (`y_encoded`), \n",
    "detects outliers based on how isolated each sample is compared to its local neighborhood, \n",
    "and returns a cleaned dataset with outliers removed.\n",
    "\n",
    "After detecting outliers: \n",
    " - Filters out all samples labeled as outliers\n",
    " - Returns the cleaned feature matrix and labels\n",
    " - Visualizes inliers and outliers using the first two features\n",
    "\n",
    "From the plot, the outliers (red Xs) appear randomly scattered away from high-density regions. This suggests random measurement errors or extreme anomalies \n",
    "as there is no visible structure or cluster pattern among the outliers.\n",
    "- They do not group into a separate meaningful cluster.\n",
    "- They do not represent a rare class.\n",
    "- They are unlikely to contain useful information\n",
    "\n",
    "Therefore, we decided to remove these found outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814e3110",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean, y_clean = remove_outliers(X_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a26436",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "Perform feature selection using the `SelectKBest` with `Mutual Information` as the scoring metric. \n",
    "It evaluates how informative each feature is in predicting the target labels, \n",
    "selects the top k most relevant features, and returns:\n",
    " - `X_selected`: the transformed dataset containing only the selected features\n",
    " - `selected_features`: the names of the chosen features\n",
    "\n",
    "This process helps reduce dimensionality, remove irrelevant inputs, \n",
    "and improve the performance and interpretability of ML models. \n",
    "\n",
    "Feature selection is a crucial step as without performing feature selection (see: `train_without_feature_selection.ipynb`), the model performance significantly decreases approximately `10%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a67251",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected, selected_features = select_features(X_clean, y_clean, X_raw.columns, k=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d911ad",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "Two visualizations are provided:\n",
    "- Ground truth scatter of selected features\n",
    "- k-NN decision boundary plot (using 2D PCA) to understand classifier behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc63de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_scaler = StandardScaler()\n",
    "X_selected_scaled = selected_scaler.fit_transform(X_selected)\n",
    "visualize_ground_truth(X_selected_scaled, y_clean, label_encoder)\n",
    "visualize_knn_decision_boundary(X_selected_scaled, y_clean, n_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e091967",
   "metadata": {},
   "source": [
    "## Classification\n",
    "Here we train `K-NN` classifier with hyperparameter tuning where\n",
    "we search for optimal `k`.\n",
    "\n",
    "With hyperparameter tuning, the `K-NN` classifier achieves approximately `78%` accuracy, compared to only `70%` accuracy without tuning (using `classify_with_knn_without_hyperparameter`). This shows that hyperparameter optimization provides a substantial performance gain for `K-NN`. \n",
    "\n",
    "Additionally, the poorest performance occurs when training `K-NN` without hyperparameter tuning and without feature selection, yielding only about `63%` accuracy, barely above a coin flip.\n",
    "\n",
    "## ROC Curve\n",
    "From the ROC Curve, the classifier distinguishes `Healthy` and `High Stress` extremely well, but is less confident when detecting `Moderate Stress`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88580f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier with hyperparameter\n",
    "print(\"Running KNN with hyperparameter tuning...\")\n",
    "knn = classify_with_knn(X_selected_scaled, y_clean, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4991dc13",
   "metadata": {},
   "source": [
    "## Saving Model Artifacts\n",
    "The following model components are saved for later inference (`./inference.sh`):\n",
    "- Trained k-NN model\n",
    "- Label encoder\n",
    "- Scaler for selected features\n",
    "- List of selected feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8529bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(\n",
    "    knn: KNeighborsClassifier,\n",
    "    label_encoder: LabelEncoder,\n",
    "    scaler: StandardScaler,\n",
    "    selected_features: List[str],\n",
    ") -> None:\n",
    "    path = './model'\n",
    "    joblib.dump(knn, f\"{path}/knn_model.pkl\")\n",
    "    joblib.dump(label_encoder, f\"{path}/label_encoder.pkl\")\n",
    "    joblib.dump(scaler, f\"{path}/scaler.pkl\")\n",
    "    joblib.dump(selected_features, f\"{path}/selected_features.pkl\")\n",
    "\n",
    "    print(\"Model and label encoder saved.\")\n",
    "    \n",
    "save_model(\n",
    "    knn=knn, \n",
    "    label_encoder=label_encoder, \n",
    "    scaler=selected_scaler, \n",
    "    selected_features=selected_features,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
